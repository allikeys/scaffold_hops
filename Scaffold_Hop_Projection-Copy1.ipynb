{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **services module** contains functions for accessing third party bioemdical data services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from services.pdb import pfam, pdbligand, pdbmolecule\n",
    "from services.classyfire import classyfire\n",
    "from services.uniprot import pdb2uniprot\n",
    "from services.uniprot import pdb2uniprotAC\n",
    "from services.pubchem import get_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### PDB\n",
    "For PDB we have functions for quering information about (1) PDB files, (2) Protein Molecules, (3) Ligands, (4) PFam Annotations and (5) GO annotations.  \n",
    "\n",
    "##### Uniprot\n",
    "For Uniprot we query a service that maps pdb IDs to uniprot IDs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pocket Feature Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 1. Convert pocket feature scores to \"cosine similarities\"\n",
    "\n",
    "Given a matrix $X \\in \\mathbb R ^n$ with rows $x_i$, we compute the cosine similarity between two rows as:\n",
    "\n",
    "$$ \\frac{x_i^T x_j}{\\lVert x_i \\rVert \\lVert x_j \\rVert }$$\n",
    "\n",
    "Given symmetric positive semidefinite matrix $A = X X^T$, we can compute cosine similarities using hte formula:\n",
    "\n",
    "$$\\frac{a_{ij}}{\\sqrt{a_{ii}}\\sqrt{a_{jj}}} = \\frac{x_i^T x_j}{\\lVert x_i \\rVert \\lVert x_j \\rVert }$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File ./data/pocket_feature_scores.csv does not exist: './data/pocket_feature_scores.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-1f3f1837af07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Read in pocket feature similarities and convert to an adjacency matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./data/pocket_feature_scores.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pocket_0'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pocket_1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'weight'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mpf_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpivot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pocket_0'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pocket_1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'weight'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Compute cosine similarities from pocket feature score matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File ./data/pocket_feature_scores.csv does not exist: './data/pocket_feature_scores.csv'"
     ]
    }
   ],
   "source": [
    "# Read in pocket feature similarities and convert to an adjacency matrix\n",
    "pf = pd.read_csv('./data/pocket_feature_scores.csv', header=None, names=['pocket_0', 'pocket_1', 'weight'])\n",
    "pf_matrix = pf.pivot(index='pocket_0', columns='pocket_1', values='weight')\n",
    "\n",
    "# Compute cosine similarities from pocket feature score matrix\n",
    "diagonal = np.sqrt(np.diag(-1*pf_matrix))\n",
    "denominator = np.outer(diagonal, diagonal)\n",
    "normalized = (-1*pf_matrix)/denominator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 2. Filter cosine similarities\n",
    "\n",
    "In order to reduce memory and computational costs, we filter out cosine slimilarity values that fall outside of a range of interest.  For example, we may wish to exclude low similarity values.  Likewise, we do not wish to have self referencing edges in our graph, so we also filter out diagonal values in the adjacency matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify desired range\n",
    "score_range = [0.6, 0.85]\n",
    "lower_limit = score_range[0]\n",
    "upper_limit = score_range[1]\n",
    "\n",
    "# Set matrix entries out of specificed range to NaN\n",
    "if lower_limit > 0:\n",
    "    normalized[normalized < lower_limit] = np.nan\n",
    "if upper_limit < 1:\n",
    "    normalized[normalized > upper_limit] = np.nan\n",
    "\n",
    "# Set off Diagonal to NaN\n",
    "np.fill_diagonal(normalized.values, np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 3. Initialize PF Similarity Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert from adjacency matrix to edge list\n",
    "normalized_edges = normalized.stack().reset_index()\n",
    "normalized_edges = normalized_edges.rename(columns={0:'weight'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split off ligand IDs from pocket IDs and add them as separate columns\n",
    "new = normalized_edges['pocket_0'].str.split(\"_\", expand = True)\n",
    "normalized_edges['ligand_0'] = new[1]\n",
    "\n",
    "new = normalized_edges['pocket_1'].str.split(\"_\", expand = True)\n",
    "normalized_edges['ligand_1'] = new[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize graph\n",
    "PFG = nx.Graph()\n",
    "\n",
    "# Iterate through rows of edge list dataframe\n",
    "for row in normalized_edges.itertuples():\n",
    "    \n",
    "    # If both ligand are the same, do nothing\n",
    "    ligand_0 = row.ligand_0\n",
    "    ligand_1 = row.ligand_1\n",
    "    if ligand_0 == ligand_1:\n",
    "        continue\n",
    "        \n",
    "    # If ligands are different, we pull out pocket IDs and pf cosine similarity\n",
    "    pocket_0 = row.pocket_0    \n",
    "    pocket_1 = row.pocket_1\n",
    "    weight = row.weight\n",
    "    \n",
    "    # If we have not seen this pair of ligand before, we add an edge\n",
    "    if not PFG.has_edge(ligand_0, ligand_1):\n",
    "        PFG.add_edge(ligand_0, ligand_1, id=[pocket_0, pocket_1], weight=weight)\n",
    "        \n",
    "    # Otherise update the edge weight if pf cosine similarity is greater than previous max\n",
    "    elif weight > PFG[ligand_0][ligand_1]['weight']:\n",
    "        PFG[ligand_0][ligand_1]['id'] = [pocket_0, pocket_1]\n",
    "        PFG[ligand_0][ligand_1]['weight'] = weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaffold Hop Scores\n",
    "\n",
    "We define a scaffold hop score for a pair of ligands as:\n",
    "\n",
    "$$max\\left(\\frac{F(m_1, m_2)}{T(m_1,m_2)}\\right)$$\n",
    "\n",
    "Where $m_i$ denotes a ligand in our dataset, $F$ is the pocket feature cosine similarity between bound protein structures, and $T$ is the tanomoto coefficient between chemical fingerprints.  Ligands may be bound in multiple co-crystal structures, and for any pair of ligands there may be a range of scaffold hop scores.  We take the maximum value.  In general, the high scaffold hop scores corrspond to ligands with dissimilar strucutres, that bind slimilar protein pockets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import ligand tanomoto matrix\n",
    "ligand_matrix = pd.read_csv('./data/ligandComparisons.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHG = PFG.copy()\n",
    "for ligand_0, ligand_1 in PFG.edges:\n",
    "    ligand_score = ligand_matrix[ligand_0][ligand_1]\n",
    "    pf_score = PFG[ligand_0][ligand_1]['weight']\n",
    "    \n",
    "    SHG[ligand_0][ligand_1]['weight'] = pf_score/ligand_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    # Legacy Python that doesn't verify HTTPS certificates by default\n",
    "    pass\n",
    "else:\n",
    "    # Handle target environment that doesn't support HTTPS verification\n",
    "    ssl._create_default_https_context = _create_unverified_https_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networkx.algorithms import bipartite\n",
    "\n",
    "def projected_graph(Graph):\n",
    "    nx.set_node_attributes(Graph, bipartite.color(Graph), name='color')\n",
    "\n",
    "    top = [i for i in Graph.nodes if Graph.nodes[i]['color'] == 1]\n",
    "    projected = bipartite.overlap_weighted_projected_graph(Graph, top)\n",
    "    return projected\n",
    "\n",
    "all_pockets = []\n",
    "for u,v in SHG.edges:\n",
    "    pockets = SHG[u][v]['id']\n",
    "    all_pockets.extend(pockets)\n",
    "    \n",
    "structures, ligands = zip( *[i.split('_') for i in set(all_pockets)] )\n",
    "structures = list(set(structures))\n",
    "\n",
    "pdb_uniprot_mapping = pd.read_csv(pdb2uniprot(structures), sep='\\t')\n",
    "\n",
    "PUG = nx.from_pandas_edgelist(pdb_uniprot_mapping, source='From', target='To')\n",
    "uniprot_filter = projected_graph(PUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = SHG.copy()\n",
    "for u,v in SHG.edges:\n",
    "    try:\n",
    "        pdb_0, pdb_1 = [i.split('_')[0] for i in filtered[u][v]['id']]\n",
    "        if uniprot_filter[pdb_0][pdb_1]['weight'] >= 0.5:\n",
    "            filtered.remove_edge(u,v)\n",
    "    except KeyError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Looking for affinities specific to 4J33\n",
    "for ligand_0, ligand_1 in PFG.edges:\n",
    "    pockets = SHG[ligand_0][ligand_1]['id']\n",
    "    if (ligand_0 == 'FAD' or ligand_1 == 'FAD'): \n",
    "        ligand_score = ligand_matrix[ligand_0][ligand_1]\n",
    "        pf_score = PFG[ligand_0][ligand_1]['weight']\n",
    "        #print(pockets)\n",
    "        #print(ligand_0)\n",
    "        #print(ligand_1)\n",
    "        #print(pf_score/ligand_score)\n",
    "        \n",
    "#Need to get edge data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Looking for strongest edge to 4J33\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates dict mapping pdbid to chain containing the binding pocket\n",
    "header = {0:\"pdb\", 1:\"lig\", 2:\"chain\", 3:\"num\"}\n",
    "pdbs = pd.read_csv('./data/PDB_List_Final.txt', header=None, sep='\\t')\n",
    "pdbs = pdbs.rename(columns=header)\n",
    "pdb_dict = dict(zip(pdbs.pdb, pdbs.chain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "PDB_list = pdb_dict.keys()\n",
    "\n",
    "count = 0\n",
    "\n",
    "seqDict = {}\n",
    "for mol in PDB_list:\n",
    "    chain_entry = {}\n",
    "    polymer = pdbmolecule(mol)['polymer']\n",
    "    for j in range(len(polymer)): \n",
    "        if type(polymer) == list:\n",
    "            if type(polymer[j]['chain']) == list: \n",
    "                chain = polymer[j]['chain'][0]['id']\n",
    "            else:\n",
    "                chain = polymer[j]['chain']['id']\n",
    "            if 'macroMolecule' in polymer[j]: #Else uniprotACC is empty\n",
    "                uniprotACC = polymer[j]['macroMolecule']['accession']['id']\n",
    "            else:\n",
    "                print('empty uniprot accession')\n",
    "        else: \n",
    "            if type(polymer['chain']) == list: \n",
    "                chain = polymer['chain'][0]['id']\n",
    "            else:\n",
    "                chain = polymer['chain']['id']\n",
    "            try:\n",
    "                uniprotACC = polymer['macroMolecule']['accession']['id']\n",
    "            except:\n",
    "                print(mol)\n",
    "                pprint(pdbmolecule(mol))\n",
    "                pprint(polymer)\n",
    "                print(len(polymer))\n",
    "                count += 1\n",
    "                print(f\"whoopsie! Mistake number {count}\")\n",
    "                \n",
    "        chain_entry[chain] = uniprotACC\n",
    "        seqDict[mol] = chain_entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdb_acc = {}\n",
    "for pdbid in pdb_dict.keys():\n",
    "    try: \n",
    "        pdb_acc[pdbid] = seqDict[pdbid][pdb_dict[pdbid]]\n",
    "    except:\n",
    "        missing = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "# pprint(sorted(SHG.edges(data=True), key=lambda x: x[2]['weight'], reverse=True)[:10])\n",
    "# sorted_scores = sorted(SHG.edges(data=True), key=lambda x: x[2]['weight'], reverse=True)\n",
    "\n",
    "pprint(sorted(filtered.edges(data=True), key=lambda x: x[2]['weight'], reverse=True)[:10])\n",
    "sorted_scores = sorted(filtered.edges(data=True), key=lambda x: x[2]['weight'], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as Disp\n",
    "\n",
    "# image size can be 'large' or 'small'\n",
    "image_size = 'large'\n",
    "\n",
    "# Pick an index of example to inspect \n",
    "idx = 8\n",
    "\n",
    "# everything below pulls info about example\n",
    "edge = sorted_scores[idx]\n",
    "lig_0 = edge[0]\n",
    "lig_1 = edge[1]\n",
    "\n",
    "lig_info = pdbligand( ','.join([lig_0, lig_1]) )\n",
    "keys = ['chemicalID','chemicalName', 'formula', 'molecularWeight']\n",
    "classes = []\n",
    "for info in lig_info:\n",
    "    inchi = info['InChIKey']\n",
    "    co_classes = classyfire(inchi)\n",
    "    classes.append(co_classes)\n",
    "    txt = [co_classes['direct_parent']['name'], co_classes['description']]\n",
    "    image = get_image(inchi, image_size=image_size)\n",
    "#     url = f'https://pubchem.ncbi.nlm.nih.gov/rest/pug/compound/inchikey/{inchi}/PNG?image_size={image_size}' \n",
    "#     image = requests.get(url).content\n",
    "    text = '<br>'.join( [info[key].upper() for key in keys] + txt )\n",
    "    Disp.display( Disp.Image(image), Disp.HTML(text) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pdbids(edge_data):\n",
    "    pdbs = edge_data['id']\n",
    "    return ','.join([i.split('_')[0] for i in pdbs])\n",
    "\n",
    "pprint(pdbmolecule(extract_pdbids(edge[2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
